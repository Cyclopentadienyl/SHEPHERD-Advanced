# SHEPHERD-Advanced — Unified Deployment Configuration
# Version: 3.2.0
# Consolidates platform-specific configs into single source of truth
#
# Structure:
#   - defaults: shared settings across all platforms
#   - platforms: platform-specific overrides
#   - indexing: vector index configuration
#   - paths: directory structure
#
# Platform detection: OS + arch (e.g., linux_x86_64, linux_aarch64, windows_x86_64)
# Environment variables can override any setting via SHEPHERD_<UPPERCASE_KEY>
#
# Vector Retrieval Backend Strategy (v3.2):
#   - Linux (x86/ARM): cuVS (GPU) → Voyager (CPU fallback)
#   - Windows: Voyager (CPU only, cuVS not supported on Windows)

version: "3.2"

# =============================================================================
# Default Settings (inherited by all platforms)
# =============================================================================
defaults:
  gpu_arch: blackwell
  python_version: "3.12"

  cuda:
    min_version: "12.6"
    recommended: "13.0"
    cudnn: "9"

  torch:
    version: "2.9.0"
    index_url: "https://download.pytorch.org/whl/cu130"

  attention_backend:
    # Order of preference (first available wins)
    prefer: [torch_sdpa, naive]
    allow_xformers: true
    # Environment variable to force-disable flash attention
    force_disable_env_var: FLASHATTN_FORCE_DISABLE

  retrieval_backend:
    # Default: Voyager (cross-platform CPU, always available)
    # Linux platforms will override to use cuVS (GPU) as primary
    default: voyager
    fallback_chain: [voyager]

# =============================================================================
# Platform-Specific Overrides
# =============================================================================
platforms:
  # ---------------------------------------------------------------------------
  # Linux x86_64 (Workstation / Server)
  # ---------------------------------------------------------------------------
  linux_x86_64:
    attention_backend:
      # flash_attn works well on x86
      prefer: [flash_attn, torch_sdpa, naive]
    retrieval_backend:
      # cuVS (NVIDIA RAPIDS) for GPU-accelerated vector search
      default: cuvs
      fallback_chain: [cuvs, voyager]
    indexing:
      cuvs:
        # CAGRA algorithm settings (GPU-native ANN)
        build_algo: ivf_pq
        search_algo: auto

  # ---------------------------------------------------------------------------
  # Linux aarch64 / ARM64 (DGX Spark, Grace Hopper)
  # ---------------------------------------------------------------------------
  linux_aarch64:
    machine_name: dgx_spark
    cuda:
      min_version: "13.0"
    attention_backend:
      # flash_attn NOT supported on ARM; use cuDNN SDPA or torch SDPA
      prefer: [cudnn_sdpa, torch_sdpa, naive]
    retrieval_backend:
      # cuVS supports ARM64 with CUDA 13
      default: cuvs
      fallback_chain: [cuvs, voyager]
    indexing:
      cuvs:
        build_algo: ivf_pq
        search_algo: auto
      voyager:
        # Higher values for DGX Spark's larger memory
        ef_construction: 400
        M: 48
        ef_search: 128

  # ---------------------------------------------------------------------------
  # Windows x86_64
  # ---------------------------------------------------------------------------
  windows_x86_64:
    attention_backend:
      prefer: [flash_attn, torch_sdpa, naive]
    retrieval_backend:
      # cuVS not available on Windows; use Voyager (CPU)
      default: voyager
      fallback_chain: [voyager]
    indexing:
      voyager:
        ef_construction: 200
        M: 32
        ef_search: 64

# =============================================================================
# Vector Index Configuration
# =============================================================================
indexing:
  # Embedding dimension (matches sentence-transformers model)
  dim: 768
  # Similarity metric: "ip" (inner product), "cosine", or "l2" (euclidean)
  metric: ip

  # cuVS settings (Linux GPU - NVIDIA RAPIDS)
  cuvs:
    # Algorithm: ivf_flat, ivf_pq, cagra
    build_algo: ivf_pq
    search_algo: auto
    # IVF parameters
    n_lists: 4096
    n_probes: 32

  # Voyager settings (cross-platform CPU - Spotify)
  voyager:
    # HNSW parameters
    ef_construction: 200
    M: 32
    ef_search: 64
    # Storage type: float32, float8, e4m3
    storage_type: float32

# =============================================================================
# Directory Paths
# =============================================================================
paths:
  data_root: data/
  models_root: models/
  logs_root: logs/
  cache_root: .cache/

# =============================================================================
# Feature Flags
# =============================================================================
features:
  # Enable experimental cross-species inference
  ortholog_inference: false
  # Enable PubMed literature integration
  pubmed_integration: false
  # Enable FHIR data import
  fhir_import: true
